{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HD7W0kbxkXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "399119cb-dadc-478c-9314-f439d7b1959c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# import the movie dataset\n",
        "movie = pd.read_csv('/content/drive/My Drive/Colab Notebooks/movies_data.csv')\n",
        "movie['index']=movie.index\n",
        "\n",
        "\n",
        "movie_df = movie.head(10000)\n",
        "print(movie_df)\n",
        "\n",
        "\n",
        "# select the features to predict and covert to string datatype\n",
        "features=[\"genres\",\"overview\",\"title\"]\n",
        "movie_df['genres']= movie_df['genres'].astype(str)\n",
        "movie_df['overview']= movie_df['overview'].astype(str)\n",
        "movie_df['title']= movie_df['title'].astype(str)\n",
        "\n",
        "# combine features to form one sting\n",
        "def combine_features(row):\n",
        "    return row['genres']+\" \"+row['overview']+\" \"+row['title']\n",
        "\n",
        "movie_df['combine_features']=movie_df.apply(combine_features,axis=1)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 genres  ...  index\n",
            "0     [{'id': 14, 'name': 'Fantasy'}, {'id': 35, 'na...  ...      0\n",
            "1     [{'id': 10749, 'name': 'Romance'}, {'id': 12, ...  ...      1\n",
            "2                   [{'id': 99, 'name': 'Documentary'}]  ...      2\n",
            "3                   [{'id': 99, 'name': 'Documentary'}]  ...      3\n",
            "4                         [{'id': 18, 'name': 'Drama'}]  ...      4\n",
            "...                                                 ...  ...    ...\n",
            "9995  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  ...   9995\n",
            "9996  [{'id': 35, 'name': 'Comedy'}, {'id': 10402, '...  ...   9996\n",
            "9997                      [{'id': 18, 'name': 'Drama'}]  ...   9997\n",
            "9998  [{'id': 10402, 'name': 'Music'}, {'id': 35, 'n...  ...   9998\n",
            "9999  [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name...  ...   9999\n",
            "\n",
            "[10000 rows x 5 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LHT0sjEySSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d1272aeb-869b-4684-ea4a-9643facb00a4"
      },
      "source": [
        "# The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words\n",
        "cv= CountVectorizer()\n",
        "count_matrix =cv.fit_transform(movie_df['combine_features'])\n",
        "count_matrix"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<10000x38794 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 493628 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVBX1jhWyVzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "543dbe43-2d81-49cc-bc40-5ad467dbbf3e"
      },
      "source": [
        "# Compute cosine similarity between samples\n",
        "cosine_sim = cosine_similarity(count_matrix)\n",
        "print(cosine_sim.shape)\n",
        "\n",
        "# covert similarity into ratings\n",
        "def rating_function(num):\n",
        "  if num >= 0.9:\n",
        "    return 5\n",
        "  if num >= 0.8 and num<0.9 :\n",
        "    return 4.5\n",
        "  if num >= 0.7 and num<0.8:\n",
        "    return 4\n",
        "  if num >= 0.6 and num<0.7:\n",
        "    return 3.5\n",
        "  if num >= 0.5 and num<0.6:\n",
        "    return 3\n",
        "  if num >= 0.4 and num<0.5:\n",
        "    return 2.5\n",
        "  if num >= 0.3 and num<0.4 :\n",
        "    return 2\n",
        "  if num >= 0.2 and num<0.3:\n",
        "    return 1.5\n",
        "  if num >= 0.1 and num<0.2:\n",
        "    return 1\n",
        "  if num >= 0.0 and num<0.1:\n",
        "    return 0.5  \n",
        "# making rating matrix on similarities\n",
        "for i in range(cosine_sim.shape[0]):\n",
        "  for j in range(cosine_sim.shape[1]):\n",
        "    cosine_sim[i][j] = rating_function(cosine_sim[i][j])\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCgcAjZNyWbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e50debac-15b8-4968-d5dc-358f07e72d0e"
      },
      "source": [
        "\n",
        "# converting num array into data frame\n",
        "cosine_sim_df=pd.DataFrame(data=cosine_sim,columns=movie_df['index'])\n",
        "cosine_sim_df.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmLRQBm6yXHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import user rating dataset\n",
        "rating_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ratings.csv')\n",
        "\n",
        "# making null dataframe\n",
        "rating_predicted=pd.DataFrame(data= None ,index= cosine_sim_df.index)\n",
        "\n",
        "# search for the rating which user can give to other movies based on above prediction matrix\n",
        "for index in range(0,10000) :\n",
        "  # store user_id,movie_id,movie_rating\n",
        "  user_id=rating_df.loc[index,'userId']\n",
        "  movie_id=rating_df.loc[index,'movieId']\n",
        "  movie_rating=rating_df.loc[index,'rating']\n",
        "\n",
        "  # finding the index value of movie_id from movies_data\n",
        "  ind = movie[movie['id']==movie_id].index.values\n",
        "  if len(ind)!=0 :\n",
        "    if ind[0]<10000 :\n",
        "      # storing best fitted ratings to variable rat\n",
        "      rat= cosine_sim_df[cosine_sim_df[ind[0]]==movie_rating].median(axis=0).values\n",
        "      \n",
        "\n",
        "      # adding column to null dataset created above\n",
        "      rating_predicted[user_id]= rat\n",
        "\n",
        "\n",
        "# lastly added movie ids and title of the movie to respected row\n",
        "rating_predicted['movieId']=movie_df['id']\n",
        "rating_predicted['title']=movie_df['title']\n",
        "rating_predicted.set_index('title')\n",
        "\n",
        "# print(rating_predicted)\n",
        "\n",
        "# storing csv file to memory\n",
        "rating_predicted.to_csv('predicted_ratings.csv')\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}